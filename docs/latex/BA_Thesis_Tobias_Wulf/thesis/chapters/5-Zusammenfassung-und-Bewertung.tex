% !TEX root = ../thesis.tex
% summary and conclusion
% @author Tobias Wulf
%

\chapter{Zusammenfassung und Bewertung}\label{ch:zusammenfassung-bewertung}


Dieses Kapitel fasst die Ergebnisse der Arbeit zusammen unter Berücksichtigung der Zielstellung aus \autoref{sec:zielstellung}. Erläutert wird welche Ziele erreicht worden sind und welchen Beitrag sie erbringen. Abschließend folgt ein Ausblick mit möglichen Ansätzen und Ideen, die in weiterführenden Arbeiten verfolgt werden können.


\section{Zusammenfassung}\label{sec:zusammenfassung}


Eines der wesentlichen Ziele dieser Arbeit war es vorangegangene Entwicklungsarbeiten für die Simulationssoftware des Sensor-Arrays und des Sensor-ASICs zu verbessern und zu bündeln. Dafür sind in dieser Arbeit alle bisherigen Entwurfsarbeiten aus Skripten und Funktionen in eine durch Module gegliederte Simulationssoftware überführt worden. Die Software ist zentralisiert durch ein Konfigurationsskript mit resultierender Konfigurations-MAT-Datei steuerbar. Die Software ist nun mit ordentlicher Projektstruktur versehen und kann über die Matlab-Projekt-Umgebung geöffnet werden. Beim öffnen der Software wird die Grundkonfigurierung automatisiert ausgeführt, sodass alle relevanten Projektverzeichnisse und Modulpfade in die Matlab-Umgebung eingebunden sind. Alle Entwicklungsschritte in der Matlab-Projekt-Umgebung sind unter Verwendung des Software-Versionierungsprogramms Git dokumentiert worden. Somit ist jeder Arbeitsschritt festgehalten und nachverfolgbar. Die Versionierung ist integriert in Matlab eingerichtet und innerhalb des Projektes konfiguriert. Alle in der Software verwendeten Datensätze sind in Aufbau und Funktion beschrieben. Sie sind in ihrer Verwendung nachvollziehbar dokumentiert. Die modulare Gliederung der Software und Aufteilung in Quellcode-Module und ausführbare Skripte vereinfacht den Aufbau von Simulationsprozessen und ermöglichen beliebige Erweiterungen an ausführbaren Experimenten. Die Quellcode-Module sind so angelegt, dass diese ebenfalls erweitert werden können, entsprechende Platzhalter sind dafür in der Konfiguration vorgesehen und in den Modulen mit Switch-Case-Statements vorbereitet. Am Beispiel für die Gauß-Prozess-Regression ist dies gut zu erkennen. Es ist ein Basis-Framework eingerichtet, dass einen Rahmen schafft beliebig viele Kernel-Submodule zu integrieren und über entsprechende Indikatoren in der Konfiguration in verschieden Ausführungen zu laden. So sind zwei Kernel-Submodule integriert, die jeweils als mittelwertfreie Kernel oder mit Mittelwertunterstützung durch approximierten Mittelwertpolynome betrieben werden können. Beide Kernel verwenden die gleiche Framework-Unterstützung für die Modelloptimierung. Zusätzlich sind alle Skripte und Quellcodedateien ausführlich kommentiert und dokumentiert. Für die Dokumentation des Quellcodes sind High-Level-Skripte in der Projektumgebung eingerichtet, die die Dokumentation automatisiert erstellen. Die Dokumentation ist in HTML ebenfalls in die Matlab-Projekt-Umgebung integriert. Zusätzlich liegt diese in LaTeX vor und ist zu einem Manual inklusive Workflows und Modul- sowie Projektbeschreibung kompiliert. Ebenfalls enthalten sind Templates für das Anlegen neuer Quellcode- oder Skriptdateien. Somit ist der Grundstein für eine Simulationssoftware mit hoher Wiederverwertbarkeit und Erweiterbarkeit gelegt.
\newline
Der Ansatz die Simulation für das Sensor-Array und ASIC-Modell getrennt zu halten und mittels Datensätze koppeln wurde beibehalten. Der Ansatz hat sich bewehrt und macht es leichter den Umfang der Software zu beherrschen. Die Sensor-Array-Simulation ist dahingehend erweitert worden, dass Simulationsdatensätze automatisiert und gebündelt erzeugt werden können. Es ist möglich Vektoren für Versatzparameter vorzugeben, die bei Simulationsausführung Datensätze in jeglicher Kombination erzeugen. Weitere Schachtelungen von Simulationsparameter können durch einfache For-Schleifen erzeugt werden, sodass die Durchführung von Charakterisierungen in mehrdimensionalen Parameterräumen möglich ist. Es sind Mittel und Wege in den Skripten aufgezeigt wie große Mengen an Daten indiziert, sequentiell eingelesen und verarbeitet werden können. Die Schritte dazu sind kommentiert und in Simulationsprozessen dokumentiert. Das Sensor-Array ist in seiner Ausführung konfigurierbar in Versorgungsspannung, Größe und Anzahl der Sensor-Pixel. Aktuell sind die Sensor-Pixel quadratisch mit gleichen abständen angeordnet. Platzhalter für weitere geometrische Formen sind in der Softwarekonfiguration vorbereitet. Der Encoder bzw. Magnet in der Sensor-Array-Simulation wird als approximierter Kugelmagnet betrieben und lässt sich in Magnetradius und Feldstärke dimensionieren. Zusätzlich können Startwinkel für die Rotation und Verkippung des Magneten eingestellt werden. Für die Simulation zusätzliche Parameter für Winkelanzahl, Winkelauflösung und Kennfeldnutzung stehen ebenfalls zur Verfügung. Jeweils separat zusammen mit Versatzparameter und Verkippung für Trainings- und Testdatensatzerzeugung. Es sind Kennfelddatensätze des TDK-TAS2141-AAAB TMR-Sensors und des NXP KMZ60 AMR-Sensors eingepflegt und können in der Simulation genutzt. Letzterer Kennfelddatensatz ist aus Zeitgründen nur getestet aber nicht in der Simulation verwendet worden. Es sind Unit-Tests zur Feldgenerierung und Datenerzeugung mittels Sensor-Array-Simulation durchgeführt worden, da die Datengenerierung hier die Grundlage für alle weiteren Arbeiten bildet. Für eine Auswertung der Simulationsdatensätze, Visualisierung der Kennfelddatensätze und der Magnetdimensionierung sind Plot-Funktionen in einem eigenständigen Modul angelegt worden. Die Sensor-Array-Simulation ist somit voll konfigurierbar und kann variable Datensätze automatisiert erzeugen. Die Erweiterbarkeit der Simulation ist durch modularen Aufbau hergestellt. Alle zur Simulation dazugehörigen Datensätze sind beschrieben und Dokumentiert.
\newline
Die Simulation des Sensor-ASICs mittels Gauß-Prozess-Regression ist von einem funktionalen Modellentwurf für einen Kernel in ein eigenständiges Quellcodemodul überführt worden, dass ein Framework zur Modellinitialisierung und Optimierung besitzt. In diesem Framework können nun beliebig viele weitere Kernel-Module implementiert werden. Die Gliederung in Trainingsphase und Arbeitsphase ist dabei erhalten worden. Die Trainingsphase ist um zwei Optimierungsalgorithmen erweitert worden. Der erste Optimierungsalgorithmus führt eine Trimmung der Kovarianzfunktion unter Einbezug von Trainingsdaten durch und ist eingebettet im zweiten Optimierungsalgorithmus, der die Modellgeneralisierung in Bezug auf eingespeiste Testdaten herstellt. Somit ist das empirische ermitteln von Modellparametern nicht mehr notwendig, die Optimierungsalgorithmen automatisieren diesen Teilbereich. Der Sensor ist somit jetzt vollständig lernfähig und kann bei Abweichungen sich eigenständig justieren und sich auf eine veränderte Situation anpassen. Die Optimierungsalgorithmen sind über Parametergrenzen und Durchlaufzahl konfigurierbar. Es ist der Kernel aus der Zielstellung bzw. Vorarbeiten implementiert, basierend auf diesen ist ein zweiter Kernel mit vereinfachter Abstandsfunktion implementiert. Der zweite Kernel bedingt eine Eingangswertverarbeitung der Sensor-Array-Matrixdaten. Für beide Kernel sind die Parameter der Kovarianzfunktion entsprechend der Fachliteratur interpretiert und zu Höhenskalierung und Längenskalierung der Funktion aufgeschlüsselt. Das in den Vorarbeiten noch funktional gehaltene Modell ist jetzt als Struct basiertes Modell realisiert. Beide Kernel können in zwei Varianten betrieben werden, als mittlwertfreies Modell und mit Mittelwert aus Polynomapproximation. Die Struct-Realisierung besitzt den Vorteil, dass alle Parameter und Trainingsdaten in Kombination mit Funktions-Handles in der Simulation genutzt, angezeigt und ausgewertet werden können. Zudem können mehrere Modell in einer Simulation erzeugt werden und anschließend den Framework-Funktionen für die Vorhersage und Verlust sowie Fehlerberechnung variable mit Testdaten übergeben werden. Das Struct-Modell und das dazugehörige Framework sind vollständig beschrieben und dokumentiert. Regressionsmodelle können ohne Optimierung, nur mit Trimmung oder in voller Optimierung erstellt und genutzt werden. Die Simulationssoftware ist konfigurierbar in Bezug auf Kernel-Nutzung und Parametrierung der Kovarianzfunktion, sowie in Parametrierung der Optimierungsalgorithmen und Zuschalten von Mittelwertunterstützung im Kernel. Sie ist Modular aufgebaut und kann durch weitere Kernel-Submodule ergänzt werden.
\newline
Die Experimente zur Gauß-Prozess-Regression basierend auf Datensätze aus der Sensor-Array-Simulation zeigen, dass die zweite Kernel-Implementierung ebenfalls für ein ASIC-Modell tauglich ist. Das Modell erbringt zudem Ressourceneinsparungen in Bezug auf Speicherkapazität. Trainingsdaten in diesem Modell sind im Vergleich zum Kernel aus den Vorarbeiten Skalare statt Matrizen. Zudem setzt für diesen Kernel die Generalisierung schon bei einfacher Erhöhung der Längenskalierung der Kovarianzfunktion ein. Weiterhin ist gezeigt worden, dass das Regressionsmodell im mittelwertfreien Betrieb gleich gut im Vergleich zum Mittelwert gestützten Betrieb funktioniert. Das vereinfacht eine spätere Realisierung in Hardware, da die Ermittlung der Polynomkoeffizienten für die Mittelwertbildung sehr aufwendig zu gestalten ist und anfällig für numerische Fehler ist. Im weiteren experimentellen Verlauf ist eine Optimierung in Bezug auf die Referenzwinkelanzahl unter Berücksichtigung von Berechnungszeit, Winkelfehler und Generalisierung durchgeführt worden. Ein Kompromiss ist für $N_{Ref} = 17$ Referenzwinkel gefunden worden. Des Weiteren sind Anpassungen zu Modellparametergrenzen aufgezeigt worden, die den Rechenaufwand für die Optimierungsalgorithmen minimieren können. Die Stichprobenexperimente zu Fehllagen durch Versatz und Verkippung zeigen, dass das Regressionsmodell mit Optimierung in der Lage ist Fehllagen zu kompensieren. Mittlere und maximale Fehler können dabei stark minimiert werden. Wie gut das  Modell dabei funktioniert ist abhängig von Streuungseffekten in den Messdaten, diesen können durch räumlichen Versatz, Verkippung oder Magnetfeldinhomogenität bzw. Verringerung des Abstandes zum Magneten hergestellt werden. Das Regressionsmodell hat Schwierigkeiten mit Daten umzugehen, bei denen dieser Streuungseffekt kaum oder gar nicht auftritt, sowie bei Streuungen mit gleichzeitig kleinen Signalamplituden. Das tritt ein bei Vergrößerung des Abstandes zum Magneten mit resultierender Feldstärkenabschwächung. Generell lässt sich daraus ableiten dass die Regression mit leicht bis mäßig fehlerbehafteten Daten besser Funktioniert als mit ideal homogenen oder durch Auflösungsfehler stark behafteten Daten. Das Regressionsmodell ist gegen Verkippungen bis $\SI{12}{\degree}$ resistent.


\clearpage


Die Experimente sind so angelegt das sie mit variierenden Simulationsparametern wiederholt werden können. Es sind Experimente mit räumlichen Versatz in $X$, $Y$ und $Z$ sowie Verkippung des Magneten durchgeführt worden. Alle Experimente beziehen sich auf ein $8 \times 8$ großes Sensor-Array. Das Regressionsmodell trifft in der Vorhersage von Winkeln und Radius aussagen zur Messgenauigkeit bzw. Vertrauen über Konfidenzintervalle.


\section{Ausblick}\label{sec:ausblick}


Offene Punkte sind die Einbindung des KMZ60-Kennfelddatensatzes im Simulationsbetrieb der Gauß-Prozess-Regression und die Prüfung, ob die bisher implementierten Kernel Gültigkeit für AMR-Sensoren besitzen. Durch die Stichprobenexperimente zum horizontalen Versatz deutet sich an, dass räumliche Korridore existieren, in denen die gleichen Modellparameter gleiche Resultate liefern. Unbeantwortet bleibt dabei die Frage, wie groß diese Korridore sind und ob es möglich ist Trainingsdaten anstelle Modellparametern zu tauschen, was den Aufwand in der Praxis deutlich minimieren würden. So könnten in der Fabrikation die Parameter für die Korridore ermittelt werden und im Sensor abgespeichert werden. Im späteren Einsatz in der Applikation muss dann nur ermittelt werden in welchem Korridor sich der Sensor befindet und welcher Parametersatz zum Einsatz kommen soll. Dies und das Austauschen von Trainingsdaten bzw. erneutes Einlesen, würde die sehr aufwendige Modelloptimierung in der Trainingsphase erheblich minimieren oder im besten Fall ganz ersetzen können. Dazu bedingt es weiterer Analysemethodik anhand von Sensor-Array-Rohdaten. Einen Ansatz dafür liefert die zirkulare Statistik. So können horizontaler Versatz durch Winkelhistogramme ermittelt werden, oder auch Verkippungen des Magneten über das Ausrechnen der Hauptausrichtung der Daten in Radius und Winkel \cite{Fisher1993}\cite{Mardia1999}. Ein anderer Ansatz der verfolgt werden muss, ist die Identifizierung von allgemein gültigen Testwinkeln in der Optimierung, sodass möglichst wenige zu den Trainingsdaten ergänzende Winkel angefahren werden. Momentan läuft die äußer Modelloptimierung noch bei voller Rotation mit möglichst vielen Testwinkeln. Als unbedingt nächster Schritt ist die Anbindung des Regressionsmodell an reale Messdaten zu bewältigen. Dafür muss ein Mikrocontroller gestütztes Interface realisiert werden, dass eine Frame für Frame Verarbeitung der Messdaten ermöglicht. Dafür ist eine entsprechende Funktion vorbereitet und schon in der Simulation verwendet worden. Ein weiterer Punkt ist die Wiederholung der Versatzexperimente mit nochmals reduzierter Referenzwinkelanzahl bei Betrieb des Sensors in Sättigung. Es z.Z. nicht auszuschließen, dass im Sättigungsbetrieb mit mittlerer Sensor-Pixel-Streuung noch Reserven vorhanden sind, die eine weitere Verringerung der Referenzwinkelanzahl zulassen. Die Optimierungs- und Kompensationsfähigkeit muss damit im Zusammenhang erneut geprüft werden. Ebenfalls sind noch weitere Experimente mit variierender Sensor-Pixel-Anzahl durchzuführen. Dabei gilt es zu untersuchen ob eine Erhöhung der Pixel-Anzahl zur Kompensation bei schlechter Streuung oder Auflösung beiträgt. Des Weiteren sollten die z.Z. noch eingebetteten grafischen Auswertungen der Experiment aus den Skripten in das Plot-Modul überführt werden, sodass eine Datensatz basierte Analyse vorgenommen werden kann wie für die Sensor-Array-Simulation. Damit einhergehend ist es notwendig nach Vorbild der Sensor-Array-Simulationsdatensätze Ergebnisdatensätze für die Regression zu definieren. Das sollte vor der Durchführung einer mehrdimensionalen Parametercharakterisierung geschehen, um die schiere Menge der Daten auswerten und gegebenenfalls archivieren zu können. Zusätzlich kann untersucht werden, ob die Frobenius-Norm durch einen einfacheren Effektivwertfilter ersetzt werden kann. Voraussetzung dafür ist allerdings das eine ausreichend hohe Anzahl von Sensor-Pixeln an der Mittlung teilnimmt. Rechnerisch gesehen ist die Frobenius-Norm ein Effektivwert multipliziert mit seinem Radikanten aus $\sqrt{N}$ mit $N$ Anzahl der zur Mittlung beitragenden Werte. Ist $N$ groß genug kann der Effektivwert in einem zweiten Schritt durch einen einfachen Mittelwert für Offset behaftete Daten ersetzt werden, da die Einfache Mittlung bei ausreichend hoher Anzahl $N$ den Effektivwert approximiert. Damit wäre die Frobenius-Norm durch eine einfachere Summen-Norm ersetzbar. Der Vorteil liegt klar in der einfacheren Hardware-Realisierung eines Mittelwertfilters im Vergleich zur Frobenius-Norm. Abschließend müssen alle erarbeiteten Funktionen und Algorithmen des Regressionsmodell in C/C++ nahe Bibliotheken überführt werden, um z.B. mit Matlab erste Hardware-Synthese in HDL ausführen zu können. Ein zweiter Ansatz ist hierbei die Überführung des Regressionsmodells in ein Simulink-Modell, dass ebenfalls in Matlab für HDL-Synthesen unterstützt wird. Ebenfalls abgedeckt ist dadurch das Kompilieren von C/C++ fähigen Mikrocontroller Binärdateien.

