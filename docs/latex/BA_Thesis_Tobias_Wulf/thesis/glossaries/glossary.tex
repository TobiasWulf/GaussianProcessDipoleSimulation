% !TEX root = ./thesis.tex
% list of all glossaries in thesis
% @author Tobias Wulf

% take care that all labels are unique in the whole document

%\newglossaryentry{gl:}{
%	name={},
%	description={}
%}

% glossary entries
\newglossaryentry{gl:haw}{
	name={HAW Hamburg},
	description={Die HAW Hamburg ist die Hochschule für Angewandte Wissenschaften in Hamburg und war die ehemalige Fachhochschule am Berliner Tor}
}

\newglossaryentry{gl:ags}{
	name={Arbeitsgruppe Sensorik},
	description={Die Arbeitsgruppe Sensorik steht unter Leitung von Prof. Dr.-Ing. Karl-Ragmar Riemschneider und ist unter dem Department Informations- und Elektrotechnik Teil der Fakultät Technik un Informatik an der HAW Hambug}
}


\newglossaryentry{gl:tmr}{
	name={TMR-Effekt},
	description={Tunnel-Magnetoresistiver-Effekt}
}

\newglossaryentry{gl:gmr}{
	name={GMR-Effekt},
	description={Riesiger-Magnetoresistiver-Effekt}
}

\newglossaryentry{gl:amr}{
	name={AMR-Effekt},
	description={Anisotroper-Magnetoresistiver-Effekt}
}

\newglossaryentry{gl:sensorkopf}{
	name={Sensorkopf},
	description={Signal erzeugender Teil eines Sensor-ICs, dem eine Einheit zur weiteren Signalverarbeitung 
	nachgeschaltet ist. Für die Drehwinkelerfassung besteht steht die Signalerzeugung zumeist aus zwei verdrehten Wheatstone-Brücken, deren einzel Widerstände mittels magnetoresistiven Materialien aufgebaut sind}
}


\newglossaryentry{gl:wheatstonebruecken}{
	name={Wheatstone'sche Brückenschaltungen},
	description={Messbrückenschaltung bestehend aus zwei Spannungsteilern, die parallel zu einer gemeinsamen Quelle geschaltet sind. Es wird eine Differnzspannung über die Mittelabgriffe der Spannungsteiler gemessen. Allgemein bekanntes Messprinzip. 1833 von Samuel Hunter Christie erfunden und nach dem birtischen Physiker Sir Charles Wheatstone benannt. Abgekürzt auch Wheatstone-Brücken oder in der Sensorik auch Sensorbrücken genannt. Ein Sensorkopf für die Winkelmessung setzt sich in der Regel aus zwei solch gearteter Brückenschaltungen zusammen}
}


\newglossaryentry{gl:kennfeld}{
	name={Kennfeld},
	description={Zweidimensionales Charakterisierungsabbild einer Wheatstone'schen Sensorbrücke eines magnetoresistiven Winkelsensors. Erstellt durch die Kennfeldmethode zur Charakterisierung von magnetischen Winkelsensoren}
}

\newglossaryentry{gl:kennfeldpaar}{
	name={Kennfeldpaar},
	description={Charakterisierungsergbnis der Kennfeldmethode für die Charakterisierung magnetoresistiver Winkelsensoren. Bestehend aus zwei Kennfeldern, jeweils als Repräsentanten der Wheatstone-Brücken eines Winkelsensors}
}

\newglossaryentry{gl:kennfeldmethode}{
	name={Kennfeldmethode},
	description={Charakterisierungsverfahren zur Ausmessung magnetoresitiver Winkelsensoren, bestehend aus zwei zueinander verdrehten Wheatstone-Brücken. Die resultierenden Charakterisierungergebnisse können als Kennfelddatensätze zur Simulation von magnetischen Sensoren genutzt werden}
}

\newglossaryentry{gl:kreuzspulensystem}{
	name={Kreuzspulen-System},
	description={Spulensystem in Kreuzanordnung in dessen Mitte ein zu messendes Senor-IC platziert wird. Die Spulen sind Maßanfertigungen mit ganz bestimmten Messeigenschaften. Spulenfaktoren sind speziell ausgerechnet und nachgemessen. Kernelement des Kreuzspulen-Messstandes. Eingespeiste Spulenströme erzeugen entsprechende magnetische Felder in $X$- und $Y$-Richtung. Die Spulenströme erzeugen, entsprechend der Spulenfaktoren, $H_x$- und $H_y$-Feldstärken. Die Feldstärken sind direkt proportional zu den Einspeiseströmen. Die Ströme werden über niederohmige Shunt-Widerstände mit gemessen. Die Feldstärken können so über die Spulenfaktoren zurückgerechnet und zur Auswertung genutzt werden}
}

\newglossaryentry{gl:kreuzspulenmessstand}{
	name={Kreuzspulen-Messstand},
	description={Automatisierter Messtand zur Charakterisierung von Winkelsenoren. Der Messtand nutzt ein Kreuzspulen-System, in dessen Mitte der Winkelsensor platziert ist. Das Spulensystem erzeugt ein moduliertes, langsam rotierendes Anregungsmagnetfeld. Parallel zeichnet der Messtand, die zur Charaktisierung nötigen, Spannungsausgaben des Sensors und Anregungsströme der Spulen auf. Beides erfolgt programmatisch. Die aufgezeichneten Messdaten können im Anschluss zu Kennfeldern evaluiert werden}
}

\newglossaryentry{gl:sensor-array}{
	name={Sensor-Array},
	description={Array aus geometrisch, gleichmäßig angeordneten Einzelsenoren, die messtechnische Aufgaben im Verbund bewältigen. Jeder einzelne Senor stellt dabei ein Senor-Pixel dar. Erhobene Messdaten sind entsprechend der Sensor-Array-Struktur in Matixdatenformate zu bewerten und zu behandeln}
}

\newglossaryentry{gl:sensor-pixel}{
	name={Sensor-Pixel},
	description={Einzelsensor im Sensor-Array. Allein betrachtet als vollwertiger, analoger Sensor zu betrachten. Mehrere Sensor-Pixel zusammen verschaltet ergeben ein Sensor-Array}
}

\newglossaryentry{gl:gebermagnet}{
	name={Gebermagnet},
	description={Encoder bzw. magnetischer Stimulus zur Anregung des Sensor-Arrays. In dieser Arbeit approximiert als Kugelmagnet über die Dipol-Feldgleichung}
}

\newglossaryentry{gl:trainingsdatensatz}{
	name={Trainingsdatensatz},
	description={Winkeldatensatz der Referenzwinkel und dazugehörige Trainingsdaten in dreidimensionalen Messwertmatrizen beinhaltet. Prozzesiert mitteles Sensor-Array-Simulation}
}

\newglossaryentry{gl:testdatensatz}{
	name={Testdatensatz},
	description={Winkeldatensatz der eine beliebige Anzahl an Simulationswinkel und dazugehörige Testdaten in dreidimensionalen Messwertmatrizen beinhaltet. Prozessiert mittels Sensor-Array-Simulation}
}

\newglossaryentry{gl:messwetmatrizen}{
	name={Messwertmatrizen},
	description={Dreidimensionale Matrizen die Messwerte des Sensor-Arrays beinhalten. Die erste und zweite Position korreliert mit der Anordnung des Arrays. Die dritte Dimension korreliert mit Simulationswinkeln}
}

\newglossaryentry{gl:meshgrid}{
	name={Meshgrid},
	description={Als Meshgrid ist hier die Annordung der Sensor-Pixel im Sensor-Array zu betrachten. An den einzelnen Grid-Punktern werden Magnetfelder simuliert und das Sensorverhalten abstrahiert}
}

\newglossaryentry{gl:gaus-pro-reg}{
	name={Gauß-Prozesse für Regression},
	description={Gauß- oder Gauß'sche Prozesse für Regression sind statistische Prozesse, die auf Normalverteilungen basieren und kommen in mehrdimensionalen Regressionsverfahren zur Anwendung. Dabei werden weitere Normalverteilungen über Prozessparameter gelegt, sodass das lösen von Wahrscheinlichkeitsdichteintegralen ein Ansatz zumm maschinellen etabliert werden kann}
}

\newglossaryentry{gl:kernel}{
	name={Kernel},
	description={Kernel oder auch Kernel-Funktion wird die im Gauß-Prozess zur Anwendung kommende Kovarianzfunktion genannt. Diese Maßgebend für das Verhalten des resultierenden mathematischen Modells als Kernfunktion}
}

\newglossaryentry{gl:kernelparam}{
	name={Kernel-Parameter},
	description={Kernel-Parameter sind die Parameter zur Skalierung der Kovarianzfunktion. In der Literatur sind diese oft auch als Hyperparameter bezeichnet, da ebenfalls Normalverteilungen für diese Parameter vorliegen. Die Verteilungen werden genutzt, um die gültige Parameter über das Lösen von Minimierungsproblemen mittels logarithmischer Modellplausibilitäten (engl. log. Likelihood) zu finden}
}

\newglossaryentry{gl:rauschniveau}{
	name={Rauschniveau},
	description={Engl. Noise Level. Ist ein konstanter Parameter der auf die Diagonale der Kovarianzmatrix addiert für verauschte Beobachtungen (engl. Noisy Observations). Dieser Parameter ist als Erweiteter Kernel-Parameter zu betrachten und kann in Kombination mit Modellverlusten zur Modellgeneralisierung herangezogen werden}
}


\newglossaryentry{gl:likelihoods}{
	name={Log.-Marginal-Likelihood},
	description={Übersetzt logaritmische marginale Plausibilität oder Evidenz. Ist die logarithmische Lösung von Wahrscheinlichkeitsdichteintegralen für Normalverteiltet Wahrscheinlichkeiten in Abhängigkeit von weiteren Variablen oder Parametern}
}

\newglossaryentry{gl:modellverlust}{
	name={Modellverlust},
	description={Modellverlust sind standardisierte logarithmische Verluste (engl. Loss), ähnlich wie für die Modellplausibilität wird hier ein Wahrscheinlichkeitsdichteintegral logarithmisch gelöst. Allerdings bezieht sich der Verlust auf ein Residual aus idealem Ergebnis Regressionsergebnis unter Berücksichtigung der Standardabweichung in der Regression. Modellverluste können in Bezug auf Testdaten aussagen über die Modellgeneralisierung liefern}
}


\newglossaryentry{gl:ref-model}{
	name={Regressionsmodell},
	description={Als Regressionsmodell ist hier das durch Gauß-Prozesse initilisierte Regressionsverfahren inklusive Optimierungsalgorithmen zu betrachten}
}

\newglossaryentry{gl:kovarianzmatrix}{
	name={Kovarianzmatrix},
	description={Die Kovarianzmatrix resultiert durch Kernel-Funktion und Einspeisung von Trainingsdaten in das Regressionsmodell. Sie stellt eine Autokorrelation der Traingisdaten dar und liefert Autokorrelationskoeffizienten der Daten zueinander und zu sich selbst}
}

\newglossaryentry{gl:Samples}{
	name={Samples},
	description={Samples sind in Bezug zur Gauß-Prozess-Regression ein einzelner Trainingsdatenpunkt. In der Literatur ist das oft auch als Beobachtung (engl. Observation) genannt}
}

\newglossaryentry{gl:kernelqfc}{
	name={KernelQFC},
	description={Kernel-Submodul Quadratic-Fractional-Covariance für die Gauß-Prozess-Regression. Nutz die Frobenius-Norm als Abstandsfunktion. Modelltrainingsdaten basieren hier auf Matrizen}
}

\newglossaryentry{gl:kernelqfcapx}{
	name={KernelQFCAPX},
	description={Kernel-Submodul Quadratic-Fractional-Covariance-Approximated für die Gauß-Prozess-Regression. Nutz die euklidische Norm als Abstandsfunktion. Modelltrainingsdaten basieren hier auf Vektoren bzw. Skalare. Sensor-Array-Daten in Form von Matrizen werden Eingans zu skalaren mittels Frobenius normiert}
}

\newglossaryentry{gl:trainingsphase}{
	name={Trainingsphase},
	description={In der Trainingsphase wird das Regressionsmodell anhand von Trainingsdaten initialiert und getrimmt. Die Trimmung ist die innere Modelloptimierung und eingebettet in einer äußeren Optimierung. In der äußeren Optimierung wird das Modell unter Einbezug von weiteren Testdaten generalisiert, sodass von Trainingsdaten abweichende Datensätze verarbeiten kann}
}

\newglossaryentry{gl:innere-opt}{
	name={Innere Modelloptimierung},
	description={Die innere Modelloptimierung sucht passende Kernel-Parameter unter Einbezug von Trainingsdaten. Es wird ein Minimierungsproblem über die Modellplausibilität in Abhängigkeit der Kernel-Parameter gelöst}
}

\newglossaryentry{gl:aus-opt}{
	name={Äußere Optimierung},
	description={Die äußere Optimierung sucht nach passenden Modellen unter Einbezug von Testdaten. Es wird ein Minimierungpoblem über die Modellverluste in Abhängigkeit der Testdaten und des Rauschniveaus gelöst}
}

\newglossaryentry{gl:arbeitsphase}{
	name={Arbeitsphase},
	description={In der Arbeitsphase liegt ein vollständig initialisiertes Regressionsmodell vor. Dieses kann optimiert sein. In der Arbeitsphase werden basierend auf Messwertmatrizen Vorhersagen über Winkel und Radius getroffen. Beides unterstützt und bewertet durch entsprechende Konfidenzintervalle, die Aussagen zur Messgenauigkeit treffen}
}

\newglossaryentry{gl:zero-gpr}{
	name={Mittelwertfreie Regression},
	description={Mittelwertfreie Regression oder Regressionsmodelle sind für Regressionen mittles Gauß'scher Prozesse Modelle, in denen eine Mittlung der Trainings- sowie Testdaten aktiv ist. Der Mittlung ist zu null gesetzt, daher oft auch als Zero-Mean-GPR in der Literatur zu finden. Für diese Regressionsvariante werden Vorhersagen alleinig aus}
}

\newglossaryentry{gl:poly-gpr}{
	name={Mittelwert behaftete Regression},
	description={Mittelwert behaftete Regression oder Regressionsmodelle für Regressionen mittels Gauß'scher Prozesse sind Modelle, in denen eine Mittlung der Trainings- sowie Testdaten aktiv ist. Diese beinflusst die Modellparametrierung und ist als Regression ergänzde Stützwertbildung zu verstehen. Die Mitllung ist hier dynamisch bzw. generisch über Polynomapproximation bereitgestellt. Es können beliebige Variation an Mittelwert bildenen Funktion genutzt werden}
}
