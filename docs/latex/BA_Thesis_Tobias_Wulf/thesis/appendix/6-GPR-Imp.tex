% !TEX root = ../thesis.tex
% mathematical basic for GPR
% @author Tobias Wulf
%

\chapter{Gauß-Prozess-Regression Implementierung 0.0.1 09.04.2021}\label{ch:gpr-imp}


\vspace{5mm}
\begin{table}[!htbp]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{l l c c l}
			\toprule
			\textbf{Parametergruppe}    & \textbf{Parameter}  & \textbf{Wert}                        & \textbf{Einheit} & \textbf{Kurzbeschreibung}                                           \\ \midrule
			\multirow{9}{*}{GPROptions} & kernel              & 'QFCAPX'                             & char             & Kernel-Funktion-Indikator \eqref{eq:kfun}, 'QFC' $\leftarrow d_F^2$ \\
			                            & $\theta$            & $(1,1)$                              & -                & Kernel-Parametervektor $\theta$ \eqref{eq:kparam}                   \\
			                            & $\sigma_f^2$-Bounds & $(0.1, 100)$                         & -                & Parameter-Bounds $\theta_1$ f. \autoref{alg:fminconopt}             \\
			                            & $\sigma_l$-Bounds   & $(0.1, 100)$                         & -                & Parameter-Bounds $\theta_2$ f. \autoref{alg:fminconopt}             \\
			                            & $\sigma_n^2$        & $1 \cdot 10^{-6}$                    & -                & Rauschniveau, Rauschaufschaltung \eqref{eq:addnoise}                \\
			                            & $\sigma_n^2$-Bounds & $(1 \cdot 10^{-8}, 1 \cdot 10^{-4})$ & -                & Parameter-Bounds $\sigma_n^2$ f. \autoref{alg:bayesopt}             \\
			                            & OptimRuns           & $30$                                 & -                & Durchlaufanzahl f. \autoref{alg:bayesopt}                           \\
			                            & mean                & 'zero'                               & char             & Indikator Mittelwertpolynom Ein ('poly')/ Aus ('zero')              \\
			                            & polyDegree          & $1$                                  & -                & Grad des Mittelwertpolynoms wenn mean = 'poly'                      \\ \bottomrule
		\end{tabular}}
	\caption[Gauß-Prozess-Regression-Simulationsparameter]{Gauß-Prozess-Regression-Simulationsparameter. Default-Parameter für die Prozessierung von Simulationsergebnissen aus der Sensor-Array-Simulation \autoref{ch:sensor-array-sim-imp}.}
	\label{tab:gpr-sim-params}
\end{table}


\clearpage



\section{Modellinitialisierung}\label{sec:gprinit}


\begin{algorithm}[bhp]
	\SetAlgoLined
	\KwIn{Konfigurationsdatensatz, Trainingsdatensatz $X \mapsto \alpha_{Ref}$}
	\KwResult{Regressionsmodell mit Fähigkeit zur Datensatzverabeitung aus \autoref{ch:sensor-array-sim-imp}}
	\textbf{1.} Initialisierung Modellkonfiguration $\leftarrow$ \autoref{tab:gpr-sim-params}\;
	\textbf{2.} Initialisierung $X$, $\alpha$ und $X$-Formatierung $\leftarrow$ \autoref{eq:trainds}, \autoref{eq:testds}\;
	\textbf{3.} Initialisierung Regressionsziele $\leftarrow$ \autoref{eq:gprtarget}\;
	\textbf{4.} Initialisierung Kernel-Funktion $\leftarrow$ \autoref{eq:kfun}\;
	\textbf{5.} Initialisierung Basis-Funktion $\leftarrow$ \autoref{eq:hfun}\;
	\textbf{6.} Berechnung $K(X,X|\theta) \leftarrow$ \autoref{alg:kmatrix}\;
	\textbf{7.} Rauschaufschaltung $K_y \leftarrow$ \autoref{eq:addnoise}\;
	\textbf{8.} Cholesky-Zerlegung von $K_y$ zu $L$ u. Berechnung $\log |K_y|$ $\leftarrow$ \autoref{eq:chol}\;
	\textbf{9.} Initialisierung Mittelwertpolynome $\leftarrow$ \autoref{eq:hmatrix}\;
	\textbf{10.} Berechnung Polynomkoeffizienten $\leftarrow$ jeweils \autoref{alg:beta-koeffs} f. \autoref{eq:betacoeffs}\;
	\textbf{11.} Initialisierung Mittelwertfunktion $\leftarrow$ \autoref{eq:gprmean}\;
	\textbf{12.} Berechnung Regressionsgewichte $\leftarrow$ \autoref{eq:gprweights}\;
	\textbf{13.} Berechnung Modellplausibilität $\leftarrow$ \autoref{eq:likelihoods}\;
	\caption{Modellinitialisierung mit konst. Trainingsdaten und Parametern}
	\label{alg:gprinit}
\end{algorithm}


\clearpage


\paragraph*{Trainingsdatensatz} definiert nach der kompakten Notation aus \cite{Rasmussen2006}. Ein Trainingsdatensatz $X$ beinhaltet alle Referenzwinkelstellungen $\alpha_i$ mit $X_i \mapsto \alpha_i$, nach der Beschreibung in \autoref{sec:prinzip-des-sensor-arrays} mit $X_{cos,i} = A_x$ und $X_{sin,i} = A_y$. Für die Implementierung mit \autoref{eq:de2innorm} müssen alle Trainingsdatenmatrizen normiert sein, sodass sich Vektoren als Trainingsdaten abbilden, siehe \autoref{eq:trainds}.


\begin{align}\label{eq:trainds}
	X   &= \big[ X_i, \ldots X_{N_{Ref}} \big] \qquad\qquad\qquad\quad\!  \text{f. } i = 1,2,3,\ldots,N_{Ref} \nonumber \\
	\\
	X_i &= 
		\begin{cases}
			\big[ X_{cos,i}, X_{sin,i} \big]             &\qquad \text{f. } d_F^2 \text{ \eqref{eq:df2}} \\
			\big[ \|X_{cos,i}\|_F, \|X_{sin,i}\|_F \big] &\qquad \text{f. } d_E^2 \text{ \eqref{eq:de2innorm}}
		\end{cases} \nonumber \\
	X_i & \mapsto \alpha_i \nonumber
\end{align}


\paragraph*{Testdatensatz} definiert in kompakter Schreibweise nach \cite{Rasmussen2006}. Ein Testdatensatz $X_*$ repräsentiert einen Testwinkel mit $X_* \mapsto \alpha_*$. Auch hier gilt, wie für Trainingsdatensätze $X_i \mapsto \alpha_i$, die Umschreibung nach \autoref{sec:prinzip-des-sensor-arrays} mit $X_{cos*} = A_x$ und $X_{sin*}$. Jeweils für die gewählte Implementierung ist auch hier eine Eingangsverarbeitung der Datensätze notwendig \autoref{eq:testds}, sodass die Implementierung nach \autoref{eq:de2innorm} mit Skalaren statt Matrizen arbeitet. 


\begin{align}\label{eq:testds}
	X_* &= 
	\begin{cases}
		\big[ X_{cos*}, X_{sin*} \big]             &\qquad \text{f. } d_F^2 \text{ \eqref{eq:df2}} \\
		\big[ \|X_{cos*}\|_F, \|X_{sin*}\|_F \big] &\qquad \text{f. } d_E^2 \text{ \eqref{eq:de2innorm}}
	\end{cases} \\
	X_* & \mapsto \alpha_* \nonumber
\end{align}


\clearpage


\paragraph*{Regressionsziele} sind als Spaltenvektoren nach \cite{Rasmussen2006} wie in \autoref{eq:gprtarget} definiert. Die Besonderheit hier sind zwei Zielvektoren statt, wie in der Fachliteratur \cite{Rasmussen2006} angegeben, ein Zielvektor. Abstrahiertes Regressionsziel ist der Einheitskreis, daher ergeben einfache Sinoide aus den Referenzwinkeln in \autoref{eq:gprtarget}.


\begin{align}\label{eq:gprtarget}
	y_{cos} &= (\cos \alpha_i, \ldots, \cos \alpha_{N_{Ref}})^T \qquad \text{f. } i = 1,2,3,\ldots,N_{Ref} \nonumber \\
	\\
	y_{sin} &= (\sin \alpha_i, \ldots, \sin \alpha_{N_{Ref}})^T \nonumber
\end{align}


\paragraph*{Kernel-Funktion}


\begin{align}\label{eq:kfun}
	k(X_i, X_j) &= 
		\begin{cases}
			\resizebox{.17\linewidth}{!}{$\frac{a}{b + d_F^2\langle X_i, X_j \rangle}$} &\qquad \text{f. } d_F^2 \text{ \eqref{eq:df2}} \\\\
			\resizebox{.17\linewidth}{!}{$\frac{a}{b + d_E^2\langle X_i, X_j \rangle}$} &\qquad \text{f. } d_E^2 \text{ \eqref{eq:de2innorm}}
		\end{cases} \\
\text{mit } i,j &= 1,2,3,\ldots,N_{Ref} \nonumber
\end{align}


\paragraph*{Kernel-Parameter}


\begin{equation}\label{eq:kparam}
	a = \sigma_f^2 \cdot 2 \sigma_l^2 \qquad b = 2 \sigma_l^2 \qquad \theta = \left[\sigma_f^2, \sigma_l\right]
\end{equation}


\paragraph*{Kovarianzmatrix}
K

\begin{algorithm}[h]
	\SetAlgoLined
	\KwIn{Kernel-Funktion $k(X_i, X_j)$, Trainingsdaten $X$, Kernel-Parameter $\theta$}
	\KwResult{$K$-Matrix $N_{Ref} \times N_{Ref}$ }
	\textbf{1.} Initialisierung Parameter $(a,b) \leftarrow \theta$ \autoref{eq:kparam}\;
	\textbf{2.} \For{$i=1,2,3,\ldots,N_{Ref}$}{
		\For{$j=1,2,3,\ldots,N_{Ref}$}{
			$K_{i,j} = k(X_i, X_j) \leftarrow$ \autoref{eq:kfun}\; 
		}
	}
	\caption{Berechnung der Kovarianzmatrix $K(X, X|\theta)$}
	\label{alg:kmatrix}
\end{algorithm}


\paragraph*{Rauschaufschaltung}


\begin{equation}\label{eq:addnoise}
	K_y = K(X, X|\theta) + \sigma_n^2 I
\end{equation}


\paragraph*{Cholesky-Zerlegung $K_y$}


\begin{align}\label{eq:chol}
		 LL^T &= K_y  \nonumber \\
		 \\
	log |K_y| &= 2 \sum_{i=1}^{N_{Ref}} \log L_{i,i} \nonumber
\end{align}


\paragraph*{Basis-Funktion}

Erstmal bis Polynom 1. Grades für Amplituden und Offset Korrektur

\begin{align}\label{eq:hfun}
	h_{cos}(X_{cos*}) &=
		\begin{cases}
			0								                          & \text{f. } m_{cos}(X_{cos*}) = 0 \\
			\big( 1, \|X_{cos*}\|_F, \|X_{cos*}\|_F^2, \ldots \big)^T & \text{f. } d_F^2 \text{ \eqref{eq:df2}, }       m_{cos}(X_{cos*}) \ne 0 \\
			\big( 1, X_{cos*}, X_{cos*}^2, \ldots \big)^T             & \text{f. } d_E^2 \text{ \eqref{eq:de2innorm}, } m_{cos}(X_{cos*}) \ne 0
		\end{cases} \nonumber \\
	\\
	h_{sin}(X_{sin*}) &=
		\begin{cases}
			0								                          & \text{f. } m_{sin}(X_{sin*}) = 0 \\
			\big( 1, \|X_{sin*}\|_F, \|X_{sin*}\|_F^2, \ldots \big)^T & \text{f. } d_F^2 \text{ \eqref{eq:df2}, }       m_{sin}(X_{sin*}) \ne 0 \\
			\big( 1, X_{sin*}, X_{sin*}^2, \ldots \big)^T             & \text{f. } d_E^2 \text{ \eqref{eq:de2innorm}, } m_{sin}(X_{sin*}) \ne 0
		\end{cases} \nonumber
\end{align}


\paragraph*{Mittelwertpolynom}


\begin{align}\label{eq:hmatrix}
	H_{cos}(X_{cos}) &=
		\begin{cases}
			0 															   &\qquad \text{f. } m_{cos}(X_{cos}) = 0 \\
			\big[ h_{cos}(X_{cos,i}),\ldots,h_{cos}(X_{cos,N_{Ref}}) \big] &\qquad \text{f. } m_{cos}(X_{cos}) \ne 0
		\end{cases} \nonumber \\
	\\
	H_{sin}(X_{cos}) &=
		\begin{cases}
			0															   &\qquad \text{f. } m_{sin}(X_{sin}) = 0 \\
			\big[ h_{sin}(X_{sin,i}),\ldots,h_{sin}(X_{sin,N_{Ref}}) \big] &\qquad \text{f. } m_{sin}(X_{sin}) \ne 0
		\end{cases} \nonumber \\
	\nonumber \\
	& \text{jeweils für alle } X_{cos} = \big[ X_{cos,i},\dots, X_{cos,N_{Ref}} \big] \text{ und } \nonumber \\
	& \text{alle } X_{sin} = \big[ X_{sin,i},\dots, X_{sin,N_{Ref}} \big] \nonumber \\
	& \text{mit } i = 1,2,3,\ldots,N_{Ref} \nonumber
\end{align}


\paragraph*{Polynomkoeffizienten}


\begin{align}\label{eq:betacoeffs}
	\beta_{cos} &= 
		\begin{cases}
			0 																	 &\qquad \text{f. } m_{cos}(X_{cos}) = 0\\
			\big( H_{cos} K_y^{-1} H_{cos}^T \big)^{-1} H_{cos} K_y^{-1} y_{cos} &\qquad \text{f. } m_{cos}(X_{cos}) \ne 0
		\end{cases} \nonumber \\
	\\
	\beta_{sin} &= 
		\begin{cases}
			0 																	 &\qquad \text{f. } m_{sin}(X_{sin}) = 0\\
			\big( H_{sin} K_y^{-1} H_{sin}^T \big)^{-1} H_{sin} K_y^{-1} y_{sin} &\qquad \text{f. } m_{sin}(X_{sin}) \ne 0
		\end{cases} \nonumber \\
	\nonumber \\
	& \text{jeweils für alle } X_{cos} = \big[ X_{cos,i},\dots, X_{cos,N_{Ref}} \big] \text{ und } \nonumber \\
	& \text{alle } X_{sin} = \big[ X_{sin,i},\dots, X_{sin,N_{Ref}} \big] \nonumber \\
	& \text{mit } i = 1,2,3,\ldots,N_{Ref} \nonumber
\end{align}


\begin{algorithm}
	\SetAlgoLined
	\KwIn{Polynommatrix $H$, Untere Dreiecksmatrix $L(K_y)$, Regressionsziel $y$}
	\KwResult{$\beta$-Koeffizienten}
	\textbf{1.} $a_0 \leftarrow$ Lösen von $K_y^{-1} y$\;
	\Indp 
		$a_0 = L^T \backslash (L \backslash y)$\;
	\Indm
	\textbf{2.} $A_1 \leftarrow$ Lösen von $H K_y^{-1} H^T$\;
	\Indp
		\For{j-te Spalte in $H^T$}{
			$V_j = L \backslash H_j^T$\;
		}
		$A_1 = V^T V$\;
	\Indm
	\textbf{3.} $L_1 \leftarrow$ $\text{cholesky}(A_1)$\;
	\textbf{4.} $A_2 \leftarrow$ Lösen von $A_1^{-1} H$\;
	\Indp
		\For{$j-te$ Spalte in $H$}{
			$V_j = L_1^T \backslash (L_1 \backslash H_j)$\;
		}
		$A_2 = V$\;
	\Indm
	\textbf{5.} $\beta = A_2 \cdot a_0$
	\caption{Berechnung der $\beta$ Polynomkoeffizienten aus \autoref{eq:betacoeffs}}
	\label{alg:beta-koeffs}
\end{algorithm}


\paragraph*{Mittelwertfunktion}


\begin{align}\label{eq:gprmean}
	m_{cos}(X_{cos(*)}) &=
		\begin{cases}
			0                                    &\qquad \text{f. mittelwertfreie Regression} \\
			H_{cos}(X_{cos}) \cdot \beta_{cos} 	 &\qquad \text{f. Trainingsdaten } X_{cos} \\
			h_{cos}(X_{cos*}) \cdot \beta_{cos} &\qquad \text{f. Testdaten } X_{cos*}
		\end{cases} \nonumber \\
	\\
	m_{sin}(X_{sin(*)}) &=
		\begin{cases}
			0                                    &\qquad \text{f. mittelwertfreie Regression} \\
			H_{sin}(X_{sin}) \cdot \beta_{sin} 	 &\qquad \text{f. Trainingsdaten } X_{sin} \\
			h_{cos}(X_{sin*}) \cdot \beta_{sin} &\qquad \text{f. Testdaten } X_{sin*}
		\end{cases} \nonumber \\
	\nonumber \\
& \text{jeweils für alle } X_{cos} = \big[ X_{cos,i},\dots, X_{cos,N_{Ref}} \big] \text{ und } \nonumber \\
& \text{alle } X_{sin} = \big[ X_{sin,i},\dots, X_{sin,N_{Ref}} \big] \nonumber \\
& \text{mit } i = 1,2,3,\ldots,N_{Ref} \nonumber
\end{align}


\paragraph*{Regressionsgewichte}


\begin{align}\label{eq:gprweights}
	\alpha_{cos} &= K_y^{-1} \cdot \big( y_{cos} - m_{cos}(X_{cos}) \big) \nonumber \\
				 &= L^T \backslash \Big(L \backslash \big( y_{cos} - m_{cos}(X_{cos}) \big) \Big) \nonumber \\
	\\
	\alpha_{sin} &= K_y^{-1} \cdot \big( y_{sin} - m_{sin}(X_{sin}) \big) \nonumber \\
				 &= L^T \backslash \Big(L \backslash \big( y_{sin} - m_{sin}(X_{cos}) \big) \Big) \nonumber \\
	\nonumber \\
& \text{jeweils für alle } X_{cos} = \big[ X_{cos,i},\dots, X_{cos,N_{Ref}} \big] \text{ und } \nonumber \\
& \text{alle } X_{sin} = \big[ X_{sin,i},\dots, X_{sin,N_{Ref}} \big] \nonumber \\
& \text{mit } i = 1,2,3,\ldots,N_{Ref} \nonumber
\end{align}


\paragraph*{Modellplausibilität}


\begin{align}\label{eq:likelihoods}
	\log p(y_{cos}|X_{cos}) &= -0,5 \Big( \big( y_{cos} - m_{cos}(X_{cos}) \big)^T \alpha_{cos} + \log|K_y| + N_{Ref} \log 2\pi  \Big) \nonumber \\
	\\
	\log p(y_{sin}|X_{sin}) &= -0,5 \Big( \big( y_{sin} - m_{sin}(X_{sin}) \big)^T \alpha_{sin} + \log|K_y| + N_{Ref} \log 2\pi  \Big) \nonumber \\
	\nonumber \\
& \text{jeweils für alle } X_{cos} = \big[ X_{cos,i},\dots, X_{cos,N_{Ref}} \big] \text{ und } \nonumber \\
& \text{alle } X_{sin} = \big[ X_{sin,i},\dots, X_{sin,N_{Ref}} \big] \nonumber \\
& \text{mit } i = 1,2,3,\ldots,N_{Ref} \nonumber	
\end{align}


\clearpage


\section{Modelloptimierung}\label{sec:gpropt}


\begin{algorithm}[htp]
	\SetAlgoLined
	\KwIn{Modell inkl. $X$, $\theta,\sigma_n^2$ $+$ Bounds $\leftarrow$ \autoref{alg:gprinit}}
	\KwResult{Optimiertes Modell mit neuen Kernel-Parameter $\theta|\sigma_n^2$, f. $\sigma_n^2 = konst.$}
	\textbf{1.} Initialisierung Fmincon-Funktion\;
	\textbf{2.} Initialisierung Parameter-Bounds $\leftarrow$ Modell-Bounds \autoref{tab:gpr-sim-params}\;
	\textbf{3.} Initialisierung Fmincon-Startwert $\leftarrow$ Model-Kernel-Parameter \autoref{tab:gpr-sim-params}\;
	\textbf{4.} Initialisierung Min-Kriterium $\tilde{R}_{\mathcal{L}} \leftarrow$ \autoref{eq:fmincon}\;
	\textbf{5.} \While{$\neg(\tilde{R}_{\mathcal{L}} = konst.$ f. $7$ Iterationen$) \wedge (\min \ne \tilde{R}_{\mathcal{L}})$}{
		Zuweisung innerhalb Parameter-Bounds $\theta \leftarrow$ Fmincon-Funktion\;
		Modell-Teilreinitialisierung $\leftarrow$ \autoref{alg:gprinit}, Schritte 6. bis 13.\;
		Berechung $\tilde{R}_{\mathcal{L}} \leftarrow$ \autoref{eq:fmincon}\;
	}
	\textbf{6.} Speichern $\theta \leftarrow$ Fmincon-Funktion\;
	\textbf{7.} Modell-Teilreinitialisierung $\leftarrow$ \autoref{alg:gprinit}, Schritte 6. bis 13.\;
	\caption{Modelloptimierung über Fmincon-Funktion f. $\sigma_n^2 = konst.$}
	\label{alg:fminconopt}
\end{algorithm}


\paragraph*{Min-Kriterium}


\begin{align}\label{eq:fmincon}
\theta|\sigma_n^2 &= \underset{\theta}{\arg\min} \tilde{R}_{\mathcal{L}}(\theta|\sigma_n^2) \qquad \text{f. } \sigma_n^2 = konst. \nonumber \\
\\
\tilde{R}_{\mathcal{L}}(\theta|\sigma_n^2) &= -\big( \log p(y_{cos}|X_{cos}, \theta, \sigma_n^2) + \log p(y_{sin}|X_{sin}, \theta, \sigma_n^2) \big) \nonumber
\end{align}


\clearpage


\section{Modellvorhersagen}


\begin{algorithm}[htp]
	\SetAlgoLined
	\KwIn{Modell inkl. $X$, $\theta,\sigma_n^2$, Testdatensatz (inkl. Testwinkel $\alpha_*$) $X_* \mapsto \alpha_*$}
	\KwResult{Sinoide $\bar{f}_{cos*}, \bar{f}_{sin*}$, Radius $\bar{r}_*$, Winkel $\bar{\alpha}$, Sinoide Varianz $\mathbb{V}\left[ \bar{f}_* \right]$,
		Sinoide Std.-Abweichung $s_*$, Konfidenzintervalle $CIA_{95\%}, CIR_{95\%}$, std. log. Verluste $SLLA, SLLR$
	}
	\textbf{1.} Berechnung Kovarianzvektor $\mathbf{k}_* \leftarrow$ \autoref{eq:kvektor}\;
	\textbf{2.} Berechnung Varianzvorhersage $\mathbb{V}\left[ \bar{f}_* \right] \leftarrow$ \autoref{eq:predvar}\;
	\textbf{3.} Berechnung Mittelwertvorhersage $\bar{f}_{cos*}$, $\bar{f}_{sin*} \leftarrow$ \autoref{eq:predmean}\;
	\textbf{4.} Berechnung Radius $\bar{r}_*$, Winkel $\bar{\alpha}$ $\leftarrow$ \autoref{eq:predangrad}\;
	\textbf{4.} Berechnung Std.-Abweichung $s_* \leftarrow$ \autoref{eq:predstd}\;
	\textbf{6.} Berechnung Konfidenzintervalle $CIA_{95\%}$, $CIR_{95\%}$ $\leftarrow$ \autoref{eq:predci}\;
	\textbf{7.} Berechnung std. log. Verluste ($SLLA$), $SLLR$ $\leftarrow$ \autoref{eq:predsll}
	\caption{Modellvorhersage f. Sinoide eines Testwinkel mit $X_* \mapsto \alpha_*$}
	\label{alg:gprvorhersage}
\end{algorithm}


\paragraph*{Kovarianzvektor}

\begin{align}\label{eq:kvektor}
	& \mathbf{k}_* =  K(X, X_* | \theta) \qquad\qquad\qquad \text{mit } \text{\autoref{alg:kmatrix}} \\
	& \text{f. Traingsdaten } X \text{ und } \text{einen Testwinkel } X_* \mapsto \alpha_* \nonumber
\end{align}


\paragraph*{Mittelwertvorhersage}


\begin{align}\label{eq:predmean}
	\bar{f}_{cos*} = m_{cos}(X_{cos*}) + \mathbf{k}_{cos*}^T \cdot \alpha_{cos} \nonumber \\
	\\
	\bar{f}_{sin*} = m_{sin}(X_{sin*}) + \mathbf{k}_{sin*}^T \cdot \alpha_{sin} \nonumber
\end{align}


\begin{align}\label{eq:predangrad}
	\bar{r}_* &= \sqrt{\bar{f}_{cos*}^2 + \bar{f}_{sin*}^2} \quad\quad\ \text{wie \autoref{eq:bahnradius}} \nonumber \\
	\\
	\bar{\alpha}_* &= \text{atan2}(\bar{f}_{sin*}, \bar{f}_{cos*}) \quad \text{wie \autoref{eq:atan2}} \nonumber
\end{align}



\paragraph*{Varianzvorhersage}


\begin{align}\label{eq:predvar}
	\mathbb{V}\left[ \bar{f}_* \right] &= k(X_*, X_*) - \mathbf{k}_*^T K_y^{-1} \mathbf{k}_* \nonumber \\
									   &= k(X_*, X_*) - v^T v \\
									   &= (\sigma_f^2 + \Delta\epsilon) - v^T v \nonumber \\
						 \text{mit } v &= L \backslash \mathbf{k}_* \text{ und } \Delta\epsilon \text{ numerischer Fehler} \nonumber
\end{align}


\paragraph*{Standardabweichung}


\begin{equation}\label{eq:predstd}
s_* = \sqrt{\mathbb{V}\left[ \bar{f}_* \right] + \sigma_n^2}
\end{equation}


\paragraph*{Qualitätskriterien}


\begin{align}\label{eq:predci}
	CIA_{95\%} &= \bar{\alpha}_* \pm \arcsin \big( z_{CDF} \cdot s_* \sqrt{2} \big) \quad \text{f. } z_{CDF} = 1,96 \leftarrow 95\% \nonumber \\
	\\
	CIR_{95\%} &= \bar{r}_* \pm z_{CDF} \cdot s_* \sqrt{2} \nonumber
\end{align}



\begin{align}\label{eq:predsll}
	SLLA &= 0,5 \cdot \bigg( \log \big( 2\pi \arcsin^2 \big( s_* \sqrt{2}) \big) + \frac{(\alpha_* - \bar{\alpha}_*)^2}{\arcsin^2 \big( s_* \sqrt{2} \big)}\bigg) \nonumber \\
	\\
	SLLR &= 0,5 \cdot \bigg( \log \big( 2\pi \big( s_* \sqrt{2} \big)^2 \big) + \frac{(1 - \bar{r}_*)^2}{\big( s_* \sqrt{2} \big)^2}\bigg) \nonumber
\end{align}


\clearpage


\section{Modellgeneralisierung}


\begin{algorithm}[htp]
	\SetAlgoLined
	\KwIn{Kofigurationsdatensatz, Trainingsdatensatz X, Testdatensatz X*}
	\KwResult{Generalisiertes Modell mit optimierten Rauschniveau $\sigma_n^2$}
	\textbf{1.} Initialisierung Modell $\leftarrow$ \autoref{alg:gprinit}\;
	\textbf{2.} Initialisierung Rauschniveau-Bounds $\leftarrow$ \autoref{tab:gpr-sim-params}\;
	\textbf{3.} Initialisierung Min-Kriterium $MSLLA \leftarrow$ \autoref{eq:bayesopt}\;
	\textbf{4.} Initialisierung BayesOpt-Funktion mit Durchlaufzahl $\leftarrow$ \autoref{tab:gpr-sim-params}\;
	\textbf{5.} \While{Durlaufzahl nicht erreicht}{
		Zuweisung innerhalb Rauschniveau-Bounds $\sigma_n^2 \leftarrow$ BayesOpt-Funktion\;
		Modelloptimierung von 1. mit neuen $\sigma_n^2 \leftarrow$ \autoref{alg:fminconopt}\
		Berechnung f. alle Testwinkel $MSSLA \leftarrow$ \autoref{eq:bayesopt}\;
		Speichern und indizieren von $\sigma_n^2$ f. jedes Ergebnis $MSSLA$;
	}
	\textbf{6.} Entnahme von $\sigma_n^2$ bei $\min MSSLA$\;
	\textbf{7.} Speichern von $\sigma_n^2$ in 1.\;
	\textbf{8.} Finale Modelloptimierung von 1. $\leftarrow$ \autoref{alg:fminconopt}\;
	\textbf{9.} Berechnung und Mittelung f. alle Testwinkel $SSLA, SLLR \leftarrow$ \autoref{eq:predsll}\;
	\caption{Modellgeneralisierung über BayesOpt-Funktion f. alle $X_* \mapsto \alpha_*$}
	\label{alg:bayesopt}
\end{algorithm}


\paragraph*{Min-Kriterium}


\begin{align}\label{eq:bayesopt}
	\sigma_n^2|X_*,\alpha_* &= \underset{\sigma_n^2}{\arg\min} \text{ } MSLLA(\sigma_n^2|X_*,\alpha_*) \nonumber \\
	\\
	MSLLA &= \frac{0,5}{N_*} \cdot \bigg( \log \big( 2\pi \arcsin^2 \big( s_* \sqrt{2} \big) \big) + \frac{(\alpha_* - \bar{\alpha}_*(X_*))^2}{\arcsin^2 \big( s_* \sqrt{2} \big)}\bigg) \nonumber
	\nonumber \\
	\nonumber \\
	& \text{mit } s_*^2 = \sigma_n^2 + \mathbb{V}\left[ \bar{f}_* \right] \text{f. alle } N_* \text{ Testdaten } X_* \nonumber \\
	& \text{und Testwinkel } X_* \mapsto \alpha_* \nonumber
\end{align}

