
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            TeX: {extensions: ["mhchem.js"]},
            extensions: ["tex2jax.js"],
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [['$','$'], ['\\(','\\)']],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: true
            },
            CommonHTML: {minScaleAdjust: 110,},
            "HTML-CSS": {
                availableFonts: ["TeX"],
                scale: 110
            }
        });
        MathJax.Hub.Queue(["Rerender", MathJax.Hub], function () {window.status="finished"});
    </script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>optimGPR</title><meta name="generator" content="MATLAB 9.9"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2021-05-01"><meta name="DC.source" content="optimGPR.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>optimGPR</h1><!--introduction--><p>Noise level optimization that implements optimized model by embedded kernel tuning process.</p><!--/introduction--><h2 id="1">Syntax</h2><pre class="language-matlab">Mdl = optimGPR(TrainDS, TestDS, GPROptions, verbose)
</pre><h2 id="2">Description</h2><p><b>Mdl = optimGPR(TrainDS, TestDS, GPROptions, verbose)</b> intiates regression model by training data and passed options. Solves min search via bayesopt for optimizing noise level. At each process step buit model is reinitiated and tuned to fit best on training data. The noise optimization can be performed by SLLA ans SLLR. Depends configuration of GPROptions. The loss computation is done on all forwarded test data.</p><h2 id="3">Examples</h2><pre class="language-matlab">load <span class="string">config.mat</span> <span class="string">PathVariables</span> <span class="string">GPROptions</span>;
TrainFiles = dir(fullfile(PathVariables.trainingDataPath, <span class="string">'Training*.mat'</span>));
TestFiles = dir(fullfile(PathVariables.testDataPath, <span class="string">'Test*.mat'</span>));
assert(~isempty(TrainFiles), <span class="string">'No training datasets found.'</span>);
assert(~isempty(TestFiles), <span class="string">'No test datasets found.'</span>);
<span class="keyword">try</span>
    TrainDS = load(fullfile(TrainFiles(1).folder, TrainFiles(1).name));
    TestDS = load(fullfile(TestFiles(1).folder, TestFiles(1).name));
<span class="keyword">catch</span> ME
    rethrow(ME)
<span class="keyword">end</span>
Mdl = optimGPR(TrainDS, TestDS, GPROptions, verbose);
[fang, frad, fcos, fsin, fcov, s, ciang, cirad] = predDS(Mdl, TestDS)
[AAED, SLLA, SLLR, SEA, SER, SEC, SES] = lossDS(Mdl, TestDS);
</pre><h2 id="4">Input Argurments</h2><p><b>TrainDS</b> loaded training data by infront processesed sensor array simulation.</p><p><b>TestDS</b> loaded test data by infront processesed sensor array simulation.</p><p><b>GPROptions</b> loaded parameter group from config.mat. Struct with options.</p><p><b>verbose</b> activates prompt for true or 1. Vice versa for false or 0.</p><h2 id="5">Output Argurments</h2><p><b>Mdl</b> fully optimized model struct with tuned hyperparameters and optimized noise level.</p><h2 id="6">Requirements</h2><div><ul><li>Other m-files required: None</li><li>Subfunctions: initGPR, tuneKernel, computeOptimCriteria, lossDS,   optimizableVariable, bayesopt</li><li>MAT-files required: None</li></ul></div><h2 id="7">See Also</h2><div><ul><li><a href="matlab:web(fullfile(docroot,'stats/bayesopt.html'))">bayesopt</a></li><li><a href="matlab:web(fullfile(docroot,'stats/optimizablevariable.html'))">optimizablevariable</a></li><li><a href="initGPR.html">initGPR</a></li><li><a href="tuneKernel.html">tuneKernel</a></li><li><a href="computeOptimCriteria.html">computeOptimCriteria</a></li><li><a href="lossDS.html">lossDS</a></li></ul></div><p>Created on March 05. 2021 by Tobias Wulf. Copyright Tobias Wulf 2021.</p><p>
<!--
Hidden Clutter.
Edited on Month DD. YYYY by Editor: Single line description.
-->
</p><pre class="codeinput"><span class="keyword">function</span> Mdl = optimGPR(TrainDS, TestDS, GPROptions, verbose)

    <span class="comment">% init model by training data and initial options</span>
    Mdl = initGPR(TrainDS, GPROptions);

    <span class="comment">% create noise variance s2n used in GPR with bounds</span>
    s2n = optimizableVariable(<span class="string">'s2n'</span>, GPROptions.s2nBounds, <span class="string">'Transform'</span>, <span class="string">'log'</span>);

    <span class="comment">% create function handle for bayes optimization</span>
    SLL = GPROptions.SLL;
    fun = @(OptVar) computeOptimCriteria(OptVar, Mdl, TestDS, SLL, verbose);

    <span class="comment">% perform bayes noise optimization</span>
    results = bayesopt(fun, s2n, <span class="keyword">...</span>
        <span class="string">'Verbose'</span>, verbose, <span class="keyword">...</span>
        <span class="string">'MaxObjectiveEvaluations'</span>, GPROptions.OptimRuns, <span class="keyword">...</span>
        <span class="string">'AcquisitionFunctionName'</span>, <span class="string">'expected-improvement-per-second'</span>);

    <span class="comment">% update options with results and reinit model and tune to final model</span>
    Mdl.s2n  = results.XAtMinObjective.s2n;
    Mdl = tuneKernel(Mdl, verbose);

    <span class="comment">% compute final loss and get mean log loss for angles and radius as</span>
    <span class="comment">% indicator of model total model fit</span>
    [~, SLLA, SLLR] = lossDS(Mdl, TestDS);
    Mdl.MSLLA = mean(SLLA);
    Mdl.MSLLR = mean(SLLR);

<span class="keyword">end</span>
</pre><p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2020b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% optimGPR
% Noise level optimization that implements optimized model by embedded kernel
% tuning process.
%
%
%% Syntax
%   Mdl = optimGPR(TrainDS, TestDS, GPROptions, verbose)
%
%
%% Description
% *Mdl = optimGPR(TrainDS, TestDS, GPROptions, verbose)* intiates regression
% model by training data and passed options. Solves min search via bayesopt for
% optimizing noise level. At each process step buit model is reinitiated and
% tuned to fit best on training data. The noise optimization can be performed by
% SLLA ans SLLR. Depends configuration of GPROptions. The loss computation is
% done on all forwarded test data.
%
%
%% Examples
%   load config.mat PathVariables GPROptions;
%   TrainFiles = dir(fullfile(PathVariables.trainingDataPath, 'Training*.mat'));
%   TestFiles = dir(fullfile(PathVariables.testDataPath, 'Test*.mat'));
%   assert(~isempty(TrainFiles), 'No training datasets found.');
%   assert(~isempty(TestFiles), 'No test datasets found.');
%   try
%       TrainDS = load(fullfile(TrainFiles(1).folder, TrainFiles(1).name));
%       TestDS = load(fullfile(TestFiles(1).folder, TestFiles(1).name));
%   catch ME
%       rethrow(ME)
%   end
%   Mdl = optimGPR(TrainDS, TestDS, GPROptions, verbose);
%   [fang, frad, fcos, fsin, fcov, s, ciang, cirad] = predDS(Mdl, TestDS)
%   [AAED, SLLA, SLLR, SEA, SER, SEC, SES] = lossDS(Mdl, TestDS);
%
%
%
%% Input Argurments
% *TrainDS* loaded training data by infront processesed sensor array simulation.
%
% *TestDS* loaded test data by infront processesed sensor array simulation.
%
% *GPROptions* loaded parameter group from config.mat. Struct with options.
%
% *verbose* activates prompt for true or 1. Vice versa for false or 0.
%
%
%% Output Argurments
% *Mdl* fully optimized model struct with tuned hyperparameters and optimized
% noise level.
%
%
%% Requirements
% * Other m-files required: None
% * Subfunctions: initGPR, tuneKernel, computeOptimCriteria, lossDS,
%   optimizableVariable, bayesopt
% * MAT-files required: None
%
%
%% See Also
% * <matlab:web(fullfile(docroot,'stats/bayesopt.html')) bayesopt>
% * <matlab:web(fullfile(docroot,'stats/optimizablevariable.html')) optimizablevariable>
% * <initGPR.html initGPR>
% * <tuneKernel.html tuneKernel>
% * <computeOptimCriteria.html computeOptimCriteria>
% * <lossDS.html lossDS>
%
%
% Created on March 05. 2021 by Tobias Wulf. Copyright Tobias Wulf 2021.
%
% <html>
% <!REPLACE_WITH_DASH_DASH
% Hidden Clutter.
% Edited on Month DD. YYYY by Editor: Single line description.
% REPLACE_WITH_DASH_DASH>
% </html>
%
function Mdl = optimGPR(TrainDS, TestDS, GPROptions, verbose)
    
    % init model by training data and initial options
    Mdl = initGPR(TrainDS, GPROptions);
    
    % create noise variance s2n used in GPR with bounds 
    s2n = optimizableVariable('s2n', GPROptions.s2nBounds, 'Transform', 'log');
    
    % create function handle for bayes optimization
    SLL = GPROptions.SLL;
    fun = @(OptVar) computeOptimCriteria(OptVar, Mdl, TestDS, SLL, verbose);
    
    % perform bayes noise optimization
    results = bayesopt(fun, s2n, ...
        'Verbose', verbose, ...
        'MaxObjectiveEvaluations', GPROptions.OptimRuns, ...
        'AcquisitionFunctionName', 'expected-improvement-per-second');
    
    % update options with results and reinit model and tune to final model
    Mdl.s2n  = results.XAtMinObjective.s2n;
    Mdl = tuneKernel(Mdl, verbose);
    
    % compute final loss and get mean log loss for angles and radius as
    % indicator of model total model fit
    [~, SLLA, SLLR] = lossDS(Mdl, TestDS);
    Mdl.MSLLA = mean(SLLA);
    Mdl.MSLLR = mean(SLLR);
    
end

##### SOURCE END #####
--></body></html>